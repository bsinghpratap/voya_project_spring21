{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "prostate-reporter",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "import heapq\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, accuracy_score, classification_report\n",
    "import joblib\n",
    "from sklearn.tree import export_graphviz\n",
    "import pydot\n",
    "import imblearn\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "import sys\n",
    "import os.path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "actual-princeton",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = \"/mnt/nfs/scratch1/hshukla/prediction_results/\"\n",
    "output_folder = \"/mnt/nfs/scratch1/hshukla/prediction_results/\"\n",
    "\n",
    "file_base = \"{}_{}_{}_{}_{}.csv\"\n",
    "ws = 7\n",
    "start_year = 2012\n",
    "end_year = 2015\n",
    "pred_year = 2016\n",
    "RANDOM_STATE = 5\n",
    "exper_num = 1\n",
    "\n",
    "original_stdout = sys.stdout\n",
    "logfile_path = 'lda{}_experiment_{}.txt'.format(ws, exper_num)\n",
    "if not os.path.exists(logfile_path):\n",
    "    file = open(logfile_path, 'a+')\n",
    "    file.write(\"Init File\\n\")\n",
    "    file.close()\n",
    "out_file = open(logfile_path, 'a+')\n",
    "sys.stdout = out_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "flying-consequence",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(base + file_base.format(\"training\", start_year, end_year, pred_year, ws))\n",
    "test_df = pd.read_csv(base + file_base.format(\"testing\", start_year, end_year, pred_year, ws))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "reported-allergy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'index', 'Unnamed: 0.1', 'Unnamed: 0.1.1', 'cik',\n",
       "       'ticker_x', 'filing_date', 'item1a_risk', 'item7_mda', 'year_x',\n",
       "       'filing_year_x', 'perm_id', 'ticker_y', 'year_y', 'company_name',\n",
       "       'is_dividend_payer', 'dps_change', 'is_dps_cut', 'z_environmental',\n",
       "       'd_environmental', 'sector', 'filing_year_y', 'risk_topic_0',\n",
       "       'risk_topic_1', 'risk_topic_2', 'risk_topic_3', 'risk_topic_4',\n",
       "       'risk_topic_5', 'risk_topic_6', 'risk_topic_7', 'risk_topic_8',\n",
       "       'risk_topic_9', 'risk_topic_10', 'risk_topic_11', 'risk_topic_12',\n",
       "       'risk_topic_13', 'risk_topic_14', 'risk_topic_15', 'risk_topic_16',\n",
       "       'risk_topic_17', 'risk_topic_18', 'risk_topic_19', 'risk_topic_20',\n",
       "       'risk_topic_21', 'risk_topic_22', 'risk_topic_23', 'risk_topic_24',\n",
       "       'risk_topic_25', 'risk_topic_26', 'risk_topic_27', 'risk_topic_28',\n",
       "       'risk_topic_29', 'mda_topic_0', 'mda_topic_1', 'mda_topic_2',\n",
       "       'mda_topic_3', 'mda_topic_4', 'mda_topic_5', 'mda_topic_6',\n",
       "       'mda_topic_7', 'mda_topic_8', 'mda_topic_9', 'mda_topic_10',\n",
       "       'mda_topic_11', 'mda_topic_12', 'mda_topic_13', 'mda_topic_14',\n",
       "       'mda_topic_15', 'mda_topic_16', 'mda_topic_17', 'mda_topic_18',\n",
       "       'mda_topic_19', 'mda_topic_20', 'mda_topic_21', 'mda_topic_22',\n",
       "       'mda_topic_23', 'mda_topic_24', 'mda_topic_25', 'mda_topic_26',\n",
       "       'mda_topic_27', 'mda_topic_28', 'mda_topic_29'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'index', 'Unnamed: 0.1', 'Unnamed: 0.1.1', 'cik',\n",
       "       'ticker_x', 'filing_date', 'item1a_risk', 'item7_mda', 'year_x',\n",
       "       'filing_year_x', 'perm_id', 'ticker_y', 'year_y', 'company_name',\n",
       "       'is_dividend_payer', 'dps_change', 'is_dps_cut', 'z_environmental',\n",
       "       'd_environmental', 'sector', 'filing_year_y', 'dps_cut_prediction',\n",
       "       'risk_topic_0', 'risk_topic_1', 'risk_topic_2', 'risk_topic_3',\n",
       "       'risk_topic_4', 'risk_topic_5', 'risk_topic_6', 'risk_topic_7',\n",
       "       'risk_topic_8', 'risk_topic_9', 'risk_topic_10', 'risk_topic_11',\n",
       "       'risk_topic_12', 'risk_topic_13', 'risk_topic_14', 'risk_topic_15',\n",
       "       'risk_topic_16', 'risk_topic_17', 'risk_topic_18', 'risk_topic_19',\n",
       "       'risk_topic_20', 'risk_topic_21', 'risk_topic_22', 'risk_topic_23',\n",
       "       'risk_topic_24', 'risk_topic_25', 'risk_topic_26', 'risk_topic_27',\n",
       "       'risk_topic_28', 'risk_topic_29', 'mda_topic_0', 'mda_topic_1',\n",
       "       'mda_topic_2', 'mda_topic_3', 'mda_topic_4', 'mda_topic_5',\n",
       "       'mda_topic_6', 'mda_topic_7', 'mda_topic_8', 'mda_topic_9',\n",
       "       'mda_topic_10', 'mda_topic_11', 'mda_topic_12', 'mda_topic_13',\n",
       "       'mda_topic_14', 'mda_topic_15', 'mda_topic_16', 'mda_topic_17',\n",
       "       'mda_topic_18', 'mda_topic_19', 'mda_topic_20', 'mda_topic_21',\n",
       "       'mda_topic_22', 'mda_topic_23', 'mda_topic_24', 'mda_topic_25',\n",
       "       'mda_topic_26', 'mda_topic_27', 'mda_topic_28', 'mda_topic_29'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(train_df.columns)\n",
    "display(test_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "nonprofit-humidity",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_documents_weights = train_df.loc[:,\"risk_topic_0\":].to_numpy().tolist()\n",
    "train_documents_labels = train_df.loc[:,\"is_dps_cut\"].to_list()\n",
    "test_documents_weights = test_df.loc[:,\"risk_topic_0\":].to_numpy().tolist()\n",
    "y_actual = test_df.loc[:,\"is_dps_cut\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "friendly-routine",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 4768, 1: 387})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "5155.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{0: 1.0811661073825503, 1: 13.320413436692506}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "counter = Counter(train_documents_labels)\n",
    "total = float(sum(list(counter.values())))\n",
    "class_weights = {0: total/float(counter.get(0)), 1: total/float(counter.get(1))}\n",
    "\n",
    "display(counter)\n",
    "display(total)\n",
    "display(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "another-behavior",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics(y_real, y_predicted):\n",
    "    accuracy = accuracy_score(y_real, y_predicted)\n",
    "    precision = precision_score(y_real, y_predicted)\n",
    "    recall = recall_score(y_real, y_predicted)\n",
    "    f1 = f1_score(y_real, y_predicted)\n",
    "    print(\"Accuracy: {:.4f}\".format(accuracy))\n",
    "    print(\"Precision: {:.4f}\".format(precision))\n",
    "    print(\"Recall: {:.4f}\".format(recall))\n",
    "    print(\"F1-score: {:.4f}\".format(f1))\n",
    "    print(classification_report(y_real, y_predicted, target_names=[\"no_cut\", \"yes_cut\"]))\n",
    "    \n",
    "    cm = confusion_matrix(y_real, y_predicted)\n",
    "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    print(cm.diagonal())\n",
    "\n",
    "def train_and_validate(max_depth,samp_strat=None, class_weight=None):\n",
    "    print(\"Max_Depth: {}\".format(max_depth))\n",
    "    if class_weight:\n",
    "        print(\"Using class weighting\")\n",
    "        print(class_weight)\n",
    "        rf = RandomForestClassifier(random_state=RANDOM_STATE, n_jobs=-1, max_depth=max_depth, class_weight=class_weight)\n",
    "    else:\n",
    "        rf = RandomForestClassifier(random_state=RANDOM_STATE, n_jobs=-1, max_depth=max_depth)\n",
    "    \n",
    "    if samp_strat:\n",
    "        print(\"SMOTE sampling: {}\".format(samp_strat))\n",
    "        smote = SMOTE(sampling_strategy=samp_strat, random_state=RANDOM_STATE)\n",
    "        x_vals, y_vals = smote.fit_resample(train_documents_weights, train_documents_labels)\n",
    "    else:\n",
    "        x_vals = train_documents_weights\n",
    "        y_vals = train_documents_labels\n",
    "    \n",
    "    # Output class counts\n",
    "    counter = Counter(y_vals)\n",
    "    print(counter)\n",
    "    \n",
    "    # Fit the model\n",
    "    rf.fit(X=x_vals, y=y_vals)\n",
    "    \n",
    "    # Get training metrics first\n",
    "    print(\"- - - Train - - -\")\n",
    "    y_pred_train = rf.predict(x_vals)\n",
    "    print_metrics(y_vals, y_pred_train)\n",
    "    print()\n",
    "    \n",
    "    # Prediction metrics\n",
    "    print(\"- - - Test - - -\")\n",
    "    y_pred_test = rf.predict(test_documents_weights)\n",
    "    print(\"Cohen-Kappa: {:.4f}\".format(cohen_kappa_score(y_actual, y_pred_test)))\n",
    "    print_metrics(y_actual, y_pred_test)\n",
    "    \n",
    "        \n",
    "    print(\"\\n\")\n",
    "    print(\"----------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "passive-reduction",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hshukla/anaconda3/envs/harshulEnv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/hshukla/anaconda3/envs/harshulEnv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/hshukla/anaconda3/envs/harshulEnv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/hshukla/anaconda3/envs/harshulEnv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/hshukla/anaconda3/envs/harshulEnv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/hshukla/anaconda3/envs/harshulEnv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/hshukla/anaconda3/envs/harshulEnv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/hshukla/anaconda3/envs/harshulEnv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/hshukla/anaconda3/envs/harshulEnv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/hshukla/anaconda3/envs/harshulEnv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/hshukla/anaconda3/envs/harshulEnv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/hshukla/anaconda3/envs/harshulEnv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/hshukla/anaconda3/envs/harshulEnv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/hshukla/anaconda3/envs/harshulEnv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/hshukla/anaconda3/envs/harshulEnv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/hshukla/anaconda3/envs/harshulEnv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/hshukla/anaconda3/envs/harshulEnv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/hshukla/anaconda3/envs/harshulEnv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/hshukla/anaconda3/envs/harshulEnv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/hshukla/anaconda3/envs/harshulEnv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/hshukla/anaconda3/envs/harshulEnv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/hshukla/anaconda3/envs/harshulEnv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/hshukla/anaconda3/envs/harshulEnv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/hshukla/anaconda3/envs/harshulEnv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "depths = [3,5,7]\n",
    "sample_strategies = [.1,.3,.5,.7,1]\n",
    "for depth in depths:\n",
    "    for samp_strat in sample_strategies:\n",
    "        train_and_validate(depth,samp_strat=samp_strat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "contemporary-lover",
   "metadata": {},
   "outputs": [],
   "source": [
    "for depth in depths:\n",
    "    train_and_validate(depth,class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "weird-reason",
   "metadata": {},
   "source": [
    "# Import tools needed for visualization\n",
    "feature_names = train_df.loc[:,\"risk_topic_0\":].columns.values\n",
    "tree = rf.estimators_[0]\n",
    "\n",
    "export_graphviz(tree, out_file = 'tree.dot', feature_names = feature_names, rounded = True, precision = 1)\n",
    "(graph,) = pydot.graph_from_dot_file('tree.dot')\n",
    "graph.write_png('tree.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python harshulEnv",
   "language": "python",
   "name": "harshulenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
