{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Purpose**: This document hopes to address concerns about data loss when merging the 10-K filings + metrics, including:\n",
    "1. Losing ~30% of the 10-K filings\n",
    "2. Losing ~5% of our stock metrics\n",
    "\n",
    "**TL;DR** (read the document for graphs/methods):\n",
    "\n",
    "* **10-K Filings**\n",
    "     - 5% of 10-k filings are lost outright because they have CIKs not found in metrics\n",
    "     - Of the other 95%, 16% of the time we have data for 10-K filings but not the predictions for a given (CIK,Year). This accounts for 15% (.95 * .16) of initial 10-k filing rows.\n",
    "     - Overall, 20% of the loss is due to there not being matching data\n",
    "\n",
    "* **Stock Metrics**\n",
    "    - Around 0.5% of the metrics are lost because the CIK is not found in 10-K filings\n",
    "    - Of the other 99.5%, 2.5%-4.5% (Depending on what column we consider to be the year) of the time we have data for the metric but not the predictions for a given (CIK,Year)\n",
    "    - Overall, 3%-5% of the loss is due to there not being matching data\n",
    "    \n",
    "- Joining on different column combinations (using CIK + filing_date, year, or filing_year) makes little difference.\n",
    "- During preprocessing, grouping by CIK and using latest record removes 2% of the text rows. Even if we picked the wrong record every time this wouldn't be significant enough to explain the rest of our errors.\n",
    "\n",
    "**Maybe a different way of combining this data is needed. Still 10% of the 10-K filings and 0%-2% of the stock metrics unaccounted for.**\n",
    "- Note that in this code metrics/prediction refer to the stock events, while 10-k/text refer to the 10-k data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-05T20:07:14.786444Z",
     "start_time": "2021-03-05T20:07:13.479429Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.parsing.preprocessing import preprocess_string, remove_stopwords, strip_numeric, strip_punctuation, strip_short, stem_text\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess 10-K filings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-05T20:07:16.633742Z",
     "start_time": "2021-03-05T20:07:14.788029Z"
    }
   },
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: out of memory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-83a660737f8d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"../Files/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0myear\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2009\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2021\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mdata_by_year\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0musecols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrelevant_cols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mdata_by_year\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_by_year\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cik'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'item1a_risk'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'item7_mda'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_duplicates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mdata_by_year\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"filing_date\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_by_year\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"filing_date\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 460\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    461\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m         \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1196\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1197\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_validate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nrows\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1198\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1200\u001b[0m         \u001b[0;31m# May alter columns / col_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   2155\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2156\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2157\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2158\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2159\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: out of memory"
     ]
    }
   ],
   "source": [
    "# Load CSV\n",
    "data_by_year = {}\n",
    "relevant_cols = [\"cik\", \"ticker\", \"filing_date\", \"item1a_risk\", \"item7_mda\"]\n",
    "path = \"../Files/\"\n",
    "for year in range(2009,2021):\n",
    "    data_by_year[year] = pd.read_csv(path + str(year) + \".csv\", usecols=relevant_cols)\n",
    "    data_by_year[year] = data_by_year[year].dropna(subset=['cik', 'item1a_risk', 'item7_mda']).drop_duplicates()\n",
    "    data_by_year[year][\"filing_date\"] = pd.to_datetime(data_by_year[year][\"filing_date\"])\n",
    "    data_by_year[year][\"year\"] = year\n",
    "    data_by_year[year][\"filing_year\"] =  pd.DatetimeIndex(data_by_year[year][\"filing_date\"]).year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-05T20:07:16.636733Z",
     "start_time": "2021-03-05T20:07:13.329Z"
    }
   },
   "outputs": [],
   "source": [
    "# Dirty logic for collapsing groups. Reformat as needed - currently pretty dumb\n",
    "def collapse_cik_groups(grp):\n",
    "    if len(grp) > 1:\n",
    "        \"\"\" If the 1a and 7 text is the same, take the most recent (regardless of ticker)\"\"\"\n",
    "        if (grp.iloc[0,3] == grp[\"item1a_risk\"]).all() and (grp.iloc[0,3] == grp[\"item7_mda\"]).all():\n",
    "            # Seems like its sorted by filing_date originally - just take the last\n",
    "            return grp.iloc[-1,:]\n",
    "        else:\n",
    "            \"\"\"For now, just return the most recent\"\"\"\n",
    "            return grp.iloc[-1,:]\n",
    "    else:\n",
    "        return grp.squeeze()\n",
    "\n",
    "pre_grouping_sizes = []\n",
    "post_grouping_sizes = []\n",
    "\n",
    "for year in range(2009,2021):\n",
    "    pre_grouping_sizes.append(len(data_by_year[year]))\n",
    "    data_by_year[year] = data_by_year[year].groupby(\"cik\").apply(lambda grp: collapse_cik_groups(grp)).reset_index(drop=True)\n",
    "    post_grouping_sizes.append(len(data_by_year[year])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-05T20:07:16.637559Z",
     "start_time": "2021-03-05T20:07:13.331Z"
    }
   },
   "outputs": [],
   "source": [
    "# Output some metrics on data-loss\n",
    "for pre_size, post_size, year in zip(pre_grouping_sizes, post_grouping_sizes, list(range(2009,2021))):\n",
    "    num_lost = pre_size - post_size\n",
    "    percent_lost = float(num_lost) / float(pre_size)\n",
    "    display(\"{:n} lost {:.2%}, {} rows total\".format(year, percent_lost, num_lost))\n",
    "\n",
    "num_lost = sum(pre_grouping_sizes) - sum(post_grouping_sizes)\n",
    "percent_lost = float(num_lost) / float(sum(pre_grouping_sizes))\n",
    "display(\"In total lost {:.2%}, {} rows total\".format(percent_lost, num_lost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-05T20:07:16.638293Z",
     "start_time": "2021-03-05T20:07:13.333Z"
    }
   },
   "outputs": [],
   "source": [
    "# Concat all dataframes into a single one\n",
    "text_dfs = pd.concat(data_by_year.values(), ignore_index=True)\n",
    "text_dfs.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T18:29:52.667694Z",
     "start_time": "2021-03-01T18:16:05.590756Z"
    }
   },
   "source": [
    "# Text cleaning - omitted for now (no effect on mismatches, etc)\n",
    "\n",
    "# strip_short/strip_numeric are questionable because there are lots of relevant financial terms that are short\n",
    "# Consider removing words that are rare across documents (appear < 4 times)\n",
    "# A single year takes about 7 minutes to process. In total = mins\n",
    "#PREPROCESS_TEXT_FILTERS = [strip_punctuation, remove_stopwords, strip_numeric, stem_text, lambda x: strip_short(x, minsize=3)]\n",
    "PREPROCESS_TEXT_FILTERS = [remove_stopwords, stem_text]\n",
    "text_dfs[\"item1a_risk\"] = text_dfs[\"item1a_risk\"].apply(lambda txt: preprocess_string(txt, PREPROCESS_TEXT_FILTERS))\n",
    "text_dfs[\"item7_mda\"] = text_dfs[\"item7_mda\"].apply(lambda txt: preprocess_string(txt, PREPROCESS_TEXT_FILTERS))\n",
    "text_dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load target data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-05T20:07:16.638988Z",
     "start_time": "2021-03-05T20:07:13.360Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load predictions\n",
    "\n",
    "relevant_cols = [\"PERMID\", \"CIK\", \"Ticker\", \"year\", \"FilingDate\", \"company_name\", \"Dividend Payer\", \"DPS growth\", \"DPS cut\", \"zEnvironmental\", \"dEnvironmental\", \"sector\"]\n",
    "predictions = pd.read_excel(path + \"predictions.xlsx\", sheet_name=\"data\", skiprows=32, usecols=relevant_cols)\n",
    "predictions.columns = [\"perm_id\", \"cik\", \"ticker\", \"year\", \"filing_date\", \"company_name\", \"is_dividend_payer\", \"dps_change\", \"is_dps_cut\", \"z_environmental\", \"d_environmental\", \"sector\"]\n",
    "predictions['perm_id'] = predictions['perm_id'].str.replace(r\"[^0-9]\",'')\n",
    "predictions[\"filing_date\"] = pd.to_datetime(predictions[\"filing_date\"])\n",
    "predictions[\"filing_year\"] = pd.DatetimeIndex(predictions[\"filing_date\"]).year\n",
    "\n",
    "\"\"\" Difference in filing_date and the year (ticker AA  has 2016 w/ 2017 filing)\"\"\"\n",
    "predictions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore data pre-merge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** : Are we losing data because there isn't as much CIK overlap between the two datasets? Lets find all of the CIKs that show up in both datasets and try to figure out if the issue is the data itself or the way it is being processed.\n",
    "\n",
    "\n",
    "**Key Takeaways**:\n",
    "- 10% of the unique CIKs found in 10-k filings cannot be found in the metrics. This is unlikely to be due to pre-processing because we group by CIK and only remove rows that are duplicates. This accounts for 5% of the actual 10-k data in terms of rows. Unless we have some 3rd data source that can help us figure out changing ticker CIKs, it is unlikely this can be changed.\n",
    "- For CIKs that are found in both, existence of text data and existence of metrics data agree about 80% of the time. This means that 80% of the time we either do not have data for either, or have data for both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-05T20:07:16.640060Z",
     "start_time": "2021-03-05T20:07:13.363Z"
    }
   },
   "outputs": [],
   "source": [
    "pred_ciks = set(predictions.cik)\n",
    "text_ciks = set(text_dfs.cik)\n",
    "\n",
    "intersection = pred_ciks.intersection(text_ciks)\n",
    "union = pred_ciks.union(text_ciks)\n",
    "text_only = text_ciks.difference(pred_ciks)\n",
    "pred_only = pred_ciks.difference(text_ciks)\n",
    "\n",
    "\n",
    "display(\"Total of {:n} unique CIKs\".format(len(union)))\n",
    "display(\"# and % of CIKs in intersection: ({:n},{:.2%})\".format(len(intersection), float(len(intersection)) / float(len(union)))) \n",
    "display(\"# and % of CIKs only found in 10-K: ({:n},{:.2%})\".format(len(text_only), float(len(text_only)) / float(len(union))))\n",
    "display(\"# and % of CIKs only found in metrics: ({:n},{:.2%})\".format(len(pred_only), float(len(pred_only)) / float(len(union))))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "leftover_textdf = text_dfs[text_dfs[\"cik\"].isin(text_only)]\n",
    "leftover_preddf = predictions[predictions[\"cik\"].isin(pred_only)]\n",
    "text_loss_percent = float(len(leftover_textdf)) / float(len(text_dfs))\n",
    "metric_loss_percent = float(len(leftover_preddf)) / float(len(predictions))\n",
    "\n",
    "display(\"CIKs that only appear in the text account for {:.2%} of the text data\".format(text_loss_percent))\n",
    "display(\"CIKs that only appear in the prediction metrics account for {:.2%} of the metrics data\".format(metric_loss_percent))\n",
    "\n",
    "common_ciks = sorted(list(intersection))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-05T20:07:16.641150Z",
     "start_time": "2021-03-05T20:07:13.365Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\" Define this method to be used below\n",
    "\n",
    "    For both the 10-K text and metrics for prediction, lets create a 2D binary array where the value\n",
    "    is 1 if there is a datum for that (cik,year) and 0 otherwise. This 2D array has CIKs by row and year by column.\n",
    "    Return these binary arrays as well as their logical and (meaning data exists for both) as well as having the\n",
    "    same value (Not a mismatch)\n",
    "\"\"\"\n",
    "def find_valid(year_start, year_end, text_col, metrics_col):\n",
    "    num_years = year_end - year_start + 1\n",
    "    valid_text = []\n",
    "    valid_metrics = []\n",
    "    \n",
    "    # Find rows in our year range\n",
    "    textDF = text_dfs[(text_dfs[text_col] >= year_start) & (text_dfs[text_col] <= year_end)]\n",
    "    metricsDF = predictions[(predictions[metrics_col] >= year_start) & (predictions[metrics_col] <= year_end) ]\n",
    "    \n",
    "    # Create the binary heatmap of datum existence\n",
    "    for cik in common_ciks: #Sorted list of CIKs\n",
    "        text_binary = [0] * num_years\n",
    "        \n",
    "        # Set value to 1 in locations where we have data\n",
    "        for year in textDF[textDF.cik == cik].loc[:,text_col]:\n",
    "            text_binary[year - year_start] = 1\n",
    "        valid_text.append(text_binary)\n",
    "        \n",
    "        metric_binary = [0] * num_years\n",
    "        for year in metricsDF[metricsDF.cik == cik].loc[:,metrics_col]:\n",
    "            metric_binary[year - year_start] = 1\n",
    "        valid_metrics.append(metric_binary)\n",
    "        \n",
    "    valid_text = np.array(valid_text)\n",
    "    valid_metrics = np.array(valid_metrics)\n",
    "    binary_both = np.logical_and(valid_text, valid_metrics)\n",
    "    binary_same = valid_text == valid_metrics\n",
    "    binary_text_not_metrics = np.logical_and(valid_text, 1-valid_metrics)\n",
    "    binary_metrics_not_text = np.logical_and(1-valid_text, valid_metrics)\n",
    "    \n",
    "    total_datapoints = float(num_years * len(common_ciks))\n",
    "    display(\"# and % of present entries in text: ({:n},{:.2%})\".format(valid_text.sum(), float(valid_text.sum()) / total_datapoints)) \n",
    "    display(\"# and % of present entries in metrics: ({:n},{:.2%})\".format(valid_metrics.sum(), float(valid_metrics.sum()) / total_datapoints)) \n",
    "    display(\"# and % of present entries in text & metrics: ({:n},{:.2%})\".format(binary_both.sum(), float(binary_both.sum()) / total_datapoints))\n",
    "    display(\"# and % of entries in text & metrics that have the same value: ({:n},{:.2%})\".format(binary_same.sum(), float(binary_same.sum()) / total_datapoints))\n",
    "    display(\"% of entries where we have a value for the text but not metrics {:.2%}\".format(float(binary_text_not_metrics.sum()) / total_datapoints))\n",
    "    display(\"% of entries where we have a value for the metrics but not text {:.2%}\".format(float(binary_metrics_not_text.sum()) / total_datapoints))\n",
    "    \n",
    "    return (valid_text, valid_metrics, binary_both, binary_same)\n",
    "\n",
    "def plot_heatmap(binary_data, title, axis):\n",
    "    sns.heatmap(data=binary_data, ax=axis)\n",
    "    axis.set_title(title)\n",
    "    axis.set_xlabel(\"Years\")\n",
    "    axis.set_ylabel(\"CIK Index (Sorted)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heatmap when (Text,Metrics) use years from columns [\"year\",\"year\"] for 2009-2020 on shared CIKs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-05T20:07:16.642247Z",
     "start_time": "2021-03-05T20:07:13.368Z"
    }
   },
   "outputs": [],
   "source": [
    "binary_text, binary_metrics, binary_both, binary_same = find_valid(2009,2020, \"year\", \"year\")\n",
    "\n",
    "fig, axs = plt.subplots(2,2, figsize=(15,20))\n",
    "plot_heatmap(binary_text, \"Text Existence: [year,year] for 2009-2020\", axs[0,0])\n",
    "plot_heatmap(binary_metrics, \"Metric Existence: [year,year] for 2009-2020\", axs[0,1])\n",
    "plot_heatmap(binary_both, \"Text & Metric: [year,year] for 2009-2020\", axs[1,0])\n",
    "plot_heatmap(binary_same, \"Text == Metric: [year,year] for 2009-2020\", axs[1,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heatmap when (Text,Metrics) use years from columns [\"year\",\"year\"] 2012-2020 (Exclude 2009-2011 as we were interested in using just the 10-K text for the LDA corpus for this era, w/o prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-05T20:07:16.643122Z",
     "start_time": "2021-03-05T20:07:13.370Z"
    }
   },
   "outputs": [],
   "source": [
    "binary_text, binary_metrics, binary_both, binary_same = find_valid(2012,2020, \"year\", \"year\")\n",
    "\n",
    "fig, axs = plt.subplots(2,2, figsize=(15,20))\n",
    "plot_heatmap(binary_text, \"Text Existence: [year,year] for 2012-2020\", axs[0,0])\n",
    "plot_heatmap(binary_metrics, \"Metric Existence: [year,year] for 2012-2020\", axs[0,1])\n",
    "plot_heatmap(binary_both, \"Text & Metric: [year,year] for 2012-2020\", axs[1,0])\n",
    "plot_heatmap(binary_same, \"Text == Metric: [year,year] for 2012-2020\", axs[1,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heatmap when (Text,Metrics) use years from columns [\"year\",\"filing_year\"] 2009-2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-05T20:07:16.644256Z",
     "start_time": "2021-03-05T20:07:13.372Z"
    }
   },
   "outputs": [],
   "source": [
    "binary_text, binary_metrics, binary_both, binary_same = find_valid(2009,2020, \"year\", \"filing_year\")\n",
    "\n",
    "fig, axs = plt.subplots(2,2, figsize=(15,20))\n",
    "plot_heatmap(binary_text, \"Text Existence: [year,filing_year] for 2009-2020\", axs[0,0])\n",
    "plot_heatmap(binary_metrics, \"Metric Existence: [year,filing_year] for 2009-2020\", axs[0,1])\n",
    "plot_heatmap(binary_both, \"Text & Metric: [year,filing_year] for 2009-2020\", axs[1,0])\n",
    "plot_heatmap(binary_same, \"Text == Metric: [year,filing_year] for 2009-2020\", axs[1,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heatmap when (Text,Metrics) use years from columns [\"year\",\"filing_year\"] 2012-2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-05T20:07:16.645187Z",
     "start_time": "2021-03-05T20:07:13.377Z"
    }
   },
   "outputs": [],
   "source": [
    "binary_text, binary_metrics, binary_both, binary_same = find_valid(2012,2020, \"year\", \"filing_year\")\n",
    "\n",
    "fig, axs = plt.subplots(2,2, figsize=(15,20))\n",
    "plot_heatmap(binary_text, \"Text Existence: [year,filing_year] for 2012-2020\", axs[0,0])\n",
    "plot_heatmap(binary_metrics, \"Metric Existence: [year,filing_year] for 2012-2020\", axs[0,1])\n",
    "plot_heatmap(binary_both, \"Text & Metric: [year,filing_year] for 2012-2020\", axs[1,0])\n",
    "plot_heatmap(binary_same, \"Text == Metric: [year,filing_year] for 2012-2020\", axs[1,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Can merging on different columns help?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns of text and metrics include [\"cik\", \"filing_date\", \"filing_year\" \"year\"]. For text, year is derived from the name of the file (e.g. 2012.csv) while . Metric columns include [\"cik\", \"filing_date\", \"filing_year\", \"year\"] where filing_year is just the year from filing_date.\n",
    "- There are 6 different orientations to try (filing_date only matches with itself and we always use CIK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-05T20:07:16.646104Z",
     "start_time": "2021-03-05T20:07:13.381Z"
    }
   },
   "outputs": [],
   "source": [
    "def merge_stats(text_cols, pred_cols):\n",
    "    result = pd.merge(text_dfs, predictions, left_on=text_cols, right_on=pred_cols)\n",
    "\n",
    "    num_result = float(len(result))\n",
    "    num_text = len(text_dfs)\n",
    "    num_pred = len(predictions)\n",
    "    num_text_lost = float(num_text - num_result)\n",
    "    num_pred_lost = float(num_pred - num_result)\n",
    "\n",
    "    ticker_mismatch = result[\"ticker_x\"] != result[\"ticker_y\"]\n",
    "    \n",
    "    # filing_date_x/y don't exist if we merge on it. Make mismatch = 0\n",
    "    if (\"filing_date\" in text_cols) or (\"filing_date\" in pred_cols):\n",
    "        filing_date_mismatch = np.array([0] * int(num_result))        \n",
    "    else:\n",
    "        filing_date_mismatch = result[\"filing_date_x\"] != result[\"filing_date_y\"]\n",
    "        \n",
    "    ticker_and_filing_mismatch = ticker_mismatch & filing_date_mismatch\n",
    "    ticker_or_filing_mismatch = ticker_mismatch | filing_date_mismatch\n",
    "\n",
    "    display(\"Merging on CIK and \" + \"(\" + text_cols[1] + \",\" + pred_cols[1] +\") for (Text,pred)\")\n",
    "    display(\"     # and % of 10-K filings lost: ({:n},{:.2%})\".format(num_text_lost, num_text_lost/ num_text))\n",
    "    display(\"     # and % of stock events lost: ({:n},{:.2%})\".format(num_pred_lost, num_pred_lost/ num_pred))\n",
    "    display(\"     # and % of ticker mismatches: ({:n},{:.2%})\".format(ticker_mismatch.sum(), float(ticker_mismatch.sum()) / num_result))\n",
    "    display(\"     # and % of filing date mismatches: ({:n},{:.2%})\".format(filing_date_mismatch.sum(), float(filing_date_mismatch.sum()) / num_result))\n",
    "    display(\"     # and % of ticker and filing date mismatches: ({:n},{:.2%})\".format(ticker_and_filing_mismatch.sum(), float(ticker_and_filing_mismatch.sum()) / num_result))\n",
    "    display(\"     # and % of ticker or filing date mismatches: ({:n},{:.2%})\".format(ticker_or_filing_mismatch.sum(), float(ticker_or_filing_mismatch.sum()) / num_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-05T20:07:16.646958Z",
     "start_time": "2021-03-05T20:07:13.384Z"
    }
   },
   "outputs": [],
   "source": [
    "merge_stats([\"cik\", \"filing_date\"], [\"cik\", \"filing_date\"])\n",
    "merge_stats([\"cik\", \"filing_year\"], [\"cik\", \"filing_year\"])\n",
    "merge_stats([\"cik\", \"year\"], [\"cik\", \"year\"])\n",
    "merge_stats([\"cik\", \"year\"], [\"cik\", \"filing_year\"])\n",
    "merge_stats([\"cik\", \"filing_year\"], [\"cik\", \"year\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
