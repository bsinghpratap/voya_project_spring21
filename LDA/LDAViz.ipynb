{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Risk and MDA for window=1,5,7 for a total of 6 viz '"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "import pandas as pd\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "import pickle\n",
    "from pyLDAvis.gensim import prepare\n",
    "from pathlib import Path\n",
    "from gensim.models import CoherenceModel\n",
    "import numpy as np\n",
    "\n",
    "path_base = \"/mnt/nfs/scratch1/hshukla/sentence_results/\"\n",
    "model_base = \"sen_lda_{}_{}.model\"\n",
    "data_base = \"df_sen_{}_{}_tmp.pkl\"\n",
    "risk_label = \"item1a_risk\"\n",
    "mda_label = \"item7_mda\"\n",
    "start_year = 2012\n",
    "end_year = 2015\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "\"\"\" Risk and MDA for window=1,5,7 for a total of 6 viz \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_viz(lda_path, data, label, is_filter_extreme, ws):\n",
    "    lda_model = LdaModel.load(lda_path)\n",
    "    \n",
    "    # Load documents\n",
    "    docs_path = Path(path_base + \"{}_{}_{}_{}_{}.pkl\".format(\"documents\",start_year,end_year,label,ws))    \n",
    "    if docs_path.exists():\n",
    "        display(\"Loading Documents\")\n",
    "        with open(docs_path, \"rb\") as file:\n",
    "            documents = pickle.load(file)        \n",
    "    else:\n",
    "        display(\"Parsing Documents\")\n",
    "        data_slice = data[(data.year_x >= start_year) & (data.year_x <= end_year)]\n",
    "        documents = [sentence_grp for doc in data_slice[label].to_list() for sentence_grp in doc]\n",
    "        with open(docs_path, \"wb\") as file:\n",
    "            pickle.dump(documents, file)\n",
    "    \n",
    "    # Load dictionary\n",
    "    dict_path = Path(path_base + \"{}_{}_{}_{}_{}.pkl\".format(\"dictionary\",start_year,end_year,label,ws))\n",
    "    if dict_path.exists():\n",
    "        display(\"Loading Dict\")\n",
    "        with open(dict_path, \"rb\") as file:\n",
    "            dictionary = pickle.load(file)\n",
    "    else:\n",
    "        display(\"Parsing Dict\")\n",
    "        dictionary = Dictionary(documents)\n",
    "        if is_filter_extreme:\n",
    "            dictionary.filter_extremes(no_below=10)\n",
    "        with open(dict_path, \"wb\") as file:\n",
    "            pickle.dump(dictionary, file)\n",
    "    \n",
    "    \n",
    "    # Load corpus\n",
    "    corpus_path = Path(path_base + \"{}_{}_{}_{}_{}.pkl\".format(\"corpus\",start_year,end_year,label,ws))\n",
    "    if corpus_path.exists():\n",
    "        display(\"Loading Corpus\")\n",
    "        with open(corpus_path, \"rb\") as file:\n",
    "            corpus = pickle.load(file)\n",
    "    else:\n",
    "        display(\"Parsing Corpus\")\n",
    "        corpus = [dictionary.doc2bow(doc) for doc in documents]\n",
    "        _temp = dictionary[0] # Initialize id2token mappings\n",
    "        id2word = dictionary.id2token\n",
    "        with open(corpus_path, \"wb\") as file:\n",
    "            pickle.dump(corpus, file)\n",
    "            \n",
    "    viz_model = prepare(lda_model, corpus, dictionary=dictionary)\n",
    "    pyLDAvis.save_html(viz_model, \"{}_{}_{}_{}_{}.html\".format(\"ldaviz\",start_year,end_year,label,ws))\n",
    "    return viz_model\n",
    "    \n",
    "    \n",
    "    \n",
    "def get_coh(lda_path, data, label, is_filter_extreme, ws):\n",
    "    lda_model = LdaModel.load(lda_path)\n",
    "    \n",
    "    # Load documents\n",
    "    docs_path = Path(path_base + \"{}_{}_{}_{}_{}.pkl\".format(\"documents\",start_year,end_year,label,ws))    \n",
    "    if docs_path.exists():\n",
    "        with open(docs_path, \"rb\") as file:\n",
    "            documents = pickle.load(file)        \n",
    "    else:\n",
    "        data_slice = data[(data.year_x >= start_year) & (data.year_x <= end_year)]\n",
    "        documents = [sentence_grp for doc in data_slice[label].to_list() for sentence_grp in doc]\n",
    "        with open(docs_path, \"wb\") as file:\n",
    "            pickle.dump(documents, file)\n",
    "    \n",
    "    # Load dictionary\n",
    "    dict_path = Path(path_base + \"{}_{}_{}_{}_{}.pkl\".format(\"dictionary\",start_year,end_year,label,ws))\n",
    "    if dict_path.exists():\n",
    "        with open(dict_path, \"rb\") as file:\n",
    "            dictionary = pickle.load(file)\n",
    "    else:\n",
    "        dictionary = Dictionary(documents)\n",
    "        if is_filter_extreme:\n",
    "            dictionary.filter_extremes(no_below=10)\n",
    "        with open(dict_path, \"wb\") as file:\n",
    "            pickle.dump(dictionary, file)\n",
    "    \n",
    "    \n",
    "    # Load corpus\n",
    "    corpus_path = Path(path_base + \"{}_{}_{}_{}_{}.pkl\".format(\"corpus\",start_year,end_year,label,ws))\n",
    "    if corpus_path.exists():\n",
    "        with open(corpus_path, \"rb\") as file:\n",
    "            corpus = pickle.load(file)\n",
    "    else:\n",
    "        corpus = [dictionary.doc2bow(doc) for doc in documents]\n",
    "        _temp = dictionary[0] # Initialize id2token mappings\n",
    "        id2word = dictionary.id2token\n",
    "        with open(corpus_path, \"wb\") as file:\n",
    "            pickle.dump(corpus, file)\n",
    "    \n",
    "    cm_mass = CoherenceModel(model=lda_model, corpus=corpus, dictionary=dictionary, coherence='u_mass')\n",
    "    cm_cv = CoherenceModel(model=lda_model, texts=documents, dictionary=dictionary, coherence='c_v')\n",
    "    cm_cuci = CoherenceModel(model=lda_model, texts=documents, dictionary=dictionary, coherence='c_uci')\n",
    "    cm_npmi = CoherenceModel(model=lda_model, texts=documents, dictionary=dictionary, coherence='c_npmi')\n",
    "    \n",
    "    display(\"Umass: {:+.4f}\".format(cm_mass.get_coherence()))\n",
    "    display(\"CV: {:+.4f}\".format(cm_cv.get_coherence()))\n",
    "    display(\"CUCI: {:+.4f}\".format(cm_cuci.get_coherence()))\n",
    "    display(\"NPMI: {:+.4f}\".format(cm_npmi.get_coherence()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WindowSize = 1, WindowOverlap = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_data = pd.read_pickle(path_base + data_base.format(1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_model_base = \"window1_rerunsen_lda_{}_{}.model\"\n",
    "one_risk_lda_path = path_base + one_model_base.format(risk_label,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Loading Documents'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Loading Dict'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Loading Corpus'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "viz = get_viz(one_risk_lda_path, one_data, risk_label, True, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_coh(one_risk_lda_path, one_data, risk_label, True, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_mda_lda_path = path_base + one_model_base.format(mda_label,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Loading Documents'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Loading Dict'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Loading Corpus'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "viz = get_viz(one_mda_lda_path, one_data, mda_label, True, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_coh(one_mda_lda_path, one_data, mda_label, True, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WindowSize = 5, WindowOverlap = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "five_data = pd.read_pickle(path_base + data_base.format(5,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "five_risk_lda_path = path_base + model_base.format(risk_label,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz = get_viz(five_risk_lda_path, five_data, risk_label, True, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_coh(five_risk_lda_path, five_data, risk_label, True, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MD&A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "five_mda_lda_path = path_base + model_base.format(mda_label,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz = get_viz(five_mda_lda_path, five_data, mda_label, True, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_coh(five_mda_lda_path, five_data, mda_label, True, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WindowSize = 7, WindowOverlap = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del five_data\n",
    "seven_data = pd.read_pickle(path_base + data_base.format(7,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seven_risk_lda_path = path_base + model_base.format(risk_label,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz = get_viz(seven_risk_lda_path, seven_data, risk_label, True, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_coh(seven_risk_lda_path, seven_data, risk_label, True, 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MD&A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seven_mda_lda_path = path_base + model_base.format(mda_label,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz = get_viz(seven_mda_lda_path, seven_data, mda_label, True, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_coh(seven_mda_lda_path, seven_data, mda_label, True, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item1a = [-4.0796, -2.4353, -2.0128]\n",
    "item7 = [-5.2741, 0.5924, -2.4623]\n",
    "\n",
    "x = []\n",
    "labels = [\"1\", \"5\", \"7\"]\n",
    "x = np.arange(len(labels))\n",
    "title=\"Sentence Coherence - Umass\"\n",
    "width = 0.35  # the width of the bars\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(x - width / 2, item1a, width, label='Item1a')\n",
    "rects2 = ax.bar(x + width / 2, item7, width, label='Item7')\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_ylabel('Coherence Score')\n",
    "ax.set_xlabel('Window Size')\n",
    "ax.set_title(title)\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.legend()\n",
    "# fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item1a = [0.5407, 0.5097, 0.5316]\n",
    "item7 = [0.4854, 0.5924, 0.5446]\n",
    "\n",
    "x = []\n",
    "labels = [\"1\", \"5\", \"7\"]\n",
    "x = np.arange(len(labels))\n",
    "title=\"Sentence Coherence - C_v\"\n",
    "width = 0.35  # the width of the bars\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(x - width / 2, item1a, width, label='Item1a')\n",
    "rects2 = ax.bar(x + width / 2, item7, width, label='Item7')\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_ylabel('Coherence Score')\n",
    "ax.set_xlabel('Window Size')\n",
    "ax.set_title(title)\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.legend()\n",
    "# fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
